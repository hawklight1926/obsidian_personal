---
title: "Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning"
url: "https://arxiv.org/abs/2503.12972"
date: "2025-11-24"
updated: ""
category: "AI"
tags: []
authors: "Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang Yan, Yirong Chen, Zilin Bian, Ding Wang, Botian Shi"
image: ""
memo: ""
read: false
ignored: false
pinned: false
---

## 要約
この論文は、大規模言語モデル（LLMs）の推論能力を向上させる新しいアプローチを提案しています。
視覚情報とテキスト情報を結びつけるため、「Aligning Vision to Language」という手法を用い、アノテーションなしでマルチモーダル知識グラフを構築します。
これにより、複雑な視覚言語タスクにおいて、LLMsがより深い理解と推論を行えるようになることを目指しています。
コンピュータビジョンとパターン認識の分野において、視覚と言語の統合による知識表現の自動化が期待されます。
