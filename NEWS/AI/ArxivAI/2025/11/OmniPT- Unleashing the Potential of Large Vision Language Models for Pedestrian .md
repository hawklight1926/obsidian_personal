---
title: "OmniPT: Unleashing the Potential of Large Vision Language Models for Pedestrian Tracking and Understanding"
url: "https://arxiv.org/abs/2511.17053"
date: "2025-11-24"
updated: ""
category: "AI"
tags: []
authors: "Teng Fu, Mengyang Zhao, Ke Niu, Kaixin Peng, Bin Li"
image: ""
memo: ""
read: false
ignored: false
pinned: false
---

## 要約
本論文は、大規模視覚言語モデル（LVLM）の潜在能力を最大限に引き出し、歩行者の追跡と理解を深める新しいフレームワーク「OmniPT」を提案しています。OmniPTは、LVLMが持つ視覚とテキスト情報を統合的に処理する能力を活用することで、従来の追跡システムが抱える課題を克服することを目指します。これにより、複雑な環境下でも高精度な歩行者追跡と状況把握を可能にし、コンピュータビジョン分野におけるLVLMの応用範囲を拡大する貢献が期待されます。
