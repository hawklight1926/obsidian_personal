---
url: https://japan.zdnet.com/article/35241260/
date: 2025-12-05T08:30:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/05/58e8024e3d76fe4fe7dca824e83a1a8d/t/184/138/d/gettyimages-2201249936-cropped_hero.jpg
summary: |-
  非営利団体FLIの調査により、主要AI企業8社の安全対策が全体的に不十分であることが明らかになりました。
  - 最高評価のAnthropic、Google DeepMind、OpenAIでも「C+」や「C」と、かろうじて合格点でした。
  - 特に「存亡に関わる安全性」のカテゴリーでは全社が低評価で、強力なAIのリスク管理戦略が欠如しています。
  - 調査は、企業がスーパーインテリジェンス開発を急ぐ一方で、制御不能を防ぐ具体的な安全プロトコルが追いついていない現状を浮き彫りにしました。
read: false
ignored: false
pinned: false
memo: ""
---

![AIの安全対策が不十分な理由--グーグル、OpenAIら8社に厳しい評価](https://japan.zdnet.com/storage/2025/12/05/58e8024e3d76fe4fe7dca824e83a1a8d/t/184/138/d/gettyimages-2201249936-cropped_hero.jpg)

## 要約
非営利団体FLIの調査により、主要AI企業8社の安全対策が全体的に不十分であることが明らかになりました。
- 最高評価のAnthropic、Google DeepMind、OpenAIでも「C+」や「C」と、かろうじて合格点でした。
- 特に「存亡に関わる安全性」のカテゴリーでは全社が低評価で、強力なAIのリスク管理戦略が欠如しています。
- 調査は、企業がスーパーインテリジェンス開発を急ぐ一方で、制御不能を防ぐ具体的な安全プロトコルが追いついていない現状を浮き彫りにしました。
