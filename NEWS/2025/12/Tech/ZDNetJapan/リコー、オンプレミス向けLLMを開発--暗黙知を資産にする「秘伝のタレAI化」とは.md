---
url: https://japan.zdnet.com/article/35241363/
date: 2025-12-08T14:48:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/02/13/a79d190ed078238bb849c8f1683cd326/t/184/138/d/250213_bigdata_as_1280_1088481721.jpeg
summary: |-
  リコーはオンプレミス環境向けに、Google「Gemma 3 27B」をベースとした日本語大規模言語モデル「リコー LLM（27B）」を開発しました。
  ・270億パラメーターのコンパクトなモデルで、PCサーバーへの低コスト導入や省電力駆動を実現します。
  ・企業の暗黙知（非構造化データ）を活用するため、図表読解に強いマルチモーダルモデルや「秘伝のタレAI化」と呼ばれるAIトランスフォーメーションを推進しています。
  ・これにより、複数の専門家AIエージェントが連携して社内知識を回答に導く「秘伝のタレプラットフォーム」などを提供します。
read: false
ignored: false
pinned: false
memo: ""
---

![リコー、オンプレミス向けLLMを開発--暗黙知を資産にする「秘伝のタレAI化」とは](https://japan.zdnet.com/storage/2025/02/13/a79d190ed078238bb849c8f1683cd326/t/184/138/d/250213_bigdata_as_1280_1088481721.jpeg)

## 要約
リコーはオンプレミス環境向けに、Google「Gemma 3 27B」をベースとした日本語大規模言語モデル「リコー LLM（27B）」を開発しました。
・270億パラメーターのコンパクトなモデルで、PCサーバーへの低コスト導入や省電力駆動を実現します。
・企業の暗黙知（非構造化データ）を活用するため、図表読解に強いマルチモーダルモデルや「秘伝のタレAI化」と呼ばれるAIトランスフォーメーションを推進しています。
・これにより、複数の専門家AIエージェントが連携して社内知識を回答に導く「秘伝のタレプラットフォーム」などを提供します。
