---
url: https://japan.zdnet.com/article/35241642/
date: 2025-12-15T07:30:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg
summary: |-
  OpenAIは、AIモデルの急速な進化が「高い」レベルのサイバー兵器化リスクをもたらすと警告しています。
  - 具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成などが挙げられています。
  - 一方で、AIは防御側のツール開発や脅威特定、反復タスクの効率化にも活用できるという二面性があります。
  - これに対応するため、同社はリスクを評価・管理する「Preparedness Framework」を策定し、特にサイバーセキュリティ能力などの重点分野に対処しています。
read: false
ignored: false
pinned: false
memo: ""
---

![AIの兵器化リスクを「高い」と評価--OpenAIが公表した脅威への対抗策とは](https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg)

## 要約
OpenAIは、AIモデルの急速な進化が「高い」レベルのサイバー兵器化リスクをもたらすと警告しています。
- 具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成などが挙げられています。
- 一方で、AIは防御側のツール開発や脅威特定、反復タスクの効率化にも活用できるという二面性があります。
- これに対応するため、同社はリスクを評価・管理する「Preparedness Framework」を策定し、特にサイバーセキュリティ能力などの重点分野に対処しています。
