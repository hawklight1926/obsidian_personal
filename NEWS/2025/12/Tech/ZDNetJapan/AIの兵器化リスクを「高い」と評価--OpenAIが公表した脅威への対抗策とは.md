---
url: https://japan.zdnet.com/article/35241642/
date: 2025-12-15T07:30:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg
summary: |-
  OpenAIは、AIモデルの急速な進化がサイバーセキュリティ分野に「高い」リスクをもたらすと警告しています。
  - 具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成などが挙げられています。
  - 一方で、AIは防御側の脅威検知や効率化にも活用できるという二面性があります。
  - 同社は「Preparedness Framework」を策定し、特にサイバー能力を含む重大なリスクの評価と対策に取り組んでいます。
read: false
ignored: false
pinned: false
memo: ""
---

![AIの兵器化リスクを「高い」と評価--OpenAIが公表した脅威への対抗策とは](https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg)

## 要約
OpenAIは、AIモデルの急速な進化がサイバーセキュリティ分野に「高い」リスクをもたらすと警告しています。
- 具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成などが挙げられています。
- 一方で、AIは防御側の脅威検知や効率化にも活用できるという二面性があります。
- 同社は「Preparedness Framework」を策定し、特にサイバー能力を含む重大なリスクの評価と対策に取り組んでいます。
