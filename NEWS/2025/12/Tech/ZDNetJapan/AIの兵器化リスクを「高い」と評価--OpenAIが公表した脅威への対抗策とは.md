---
url: https://japan.zdnet.com/article/35241642/
date: 2025-12-15T07:30:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg
summary: |-
  OpenAIはAIモデルの急速な進化が「高い」サイバー兵器化リスクをもたらすと警告し、対策を開始しました。
  ・AIはブルートフォース攻撃の自動化や高度なフィッシングコンテンツ生成などに悪用される可能性があります。
  ・一方で、防御側の脅威特定ツール開発や反復タスクの自動化など、セキュリティ強化にも活用できます。
  ・同社は「Preparedness Framework」を策定し、特にサイバーセキュリティ能力などのリスクカテゴリーを監視・管理する方針です。
read: false
ignored: false
pinned: false
memo: ""
---

![AIの兵器化リスクを「高い」と評価--OpenAIが公表した脅威への対抗策とは](https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg)

## 要約
OpenAIはAIモデルの急速な進化が「高い」サイバー兵器化リスクをもたらすと警告し、対策を開始しました。
・AIはブルートフォース攻撃の自動化や高度なフィッシングコンテンツ生成などに悪用される可能性があります。
・一方で、防御側の脅威特定ツール開発や反復タスクの自動化など、セキュリティ強化にも活用できます。
・同社は「Preparedness Framework」を策定し、特にサイバーセキュリティ能力などのリスクカテゴリーを監視・管理する方針です。
