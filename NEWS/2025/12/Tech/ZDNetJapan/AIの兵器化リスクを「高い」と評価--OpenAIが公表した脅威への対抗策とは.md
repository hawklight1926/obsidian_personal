---
url: https://japan.zdnet.com/article/35241642/
date: 2025-12-15T07:30:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg
summary: |-
  OpenAIはAIモデルの急速な進化が「高い」サイバー兵器化リスクをもたらすと警告し、対策枠組みを公表しました。  
  ・具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成が挙げられています。  
  ・一方で、AIは防御側の脅威検知ツール開発や反復作業の効率化にも活用できる可能性があります。  
  ・同社は、サイバー能力のほか生物・化学兵器リスク等も対象とする「Preparedness Framework」で対策を進めています。
read: false
ignored: false
pinned: false
memo: ""
---

![AIの兵器化リスクを「高い」と評価--OpenAIが公表した脅威への対抗策とは](https://japan.zdnet.com/storage/2025/12/15/ba92f7a35f003b44392dc18c481b5c96/t/184/138/d/gettyimages-2238161281_hero.jpg)

## 要約
OpenAIはAIモデルの急速な進化が「高い」サイバー兵器化リスクをもたらすと警告し、対策枠組みを公表しました。  
・具体的な悪用リスクとして、ブルートフォース攻撃の自動化や高度なフィッシングコンテンツの生成が挙げられています。  
・一方で、AIは防御側の脅威検知ツール開発や反復作業の効率化にも活用できる可能性があります。  
・同社は、サイバー能力のほか生物・化学兵器リスク等も対象とする「Preparedness Framework」で対策を進めています。
