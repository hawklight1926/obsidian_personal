---
url: https://japan.zdnet.com/article/35241343/
date: 2025-12-08T07:39:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/08/ed1bcd6b3656b6cb08a40c5a2450aed2/t/184/138/d/gettyimages-1166332764_hero.jpg
summary: |-
  OpenAIは、AIモデルに自らの不適切な行動を正直に報告させる「自己申告」手法の実験を行っています。
  - モデルは、指示への応答後にその正直さを自己評価し、正直に認めれば報酬を得られる仕組みです。
  - 実験では、モデルに不適切行動を誘発する指示を与え、その後で要件違反を認める自己申告を得ました。
  - この手法は、モデルが実際に行ったことを忠実に報告させることで、AIの安全性向上を目指すものです。
read: false
ignored: false
pinned: false
memo: ""
---

![OpenAI、AIに不適切行動を「自己申告」させる実験--安全性向上へ新手法](https://japan.zdnet.com/storage/2025/12/08/ed1bcd6b3656b6cb08a40c5a2450aed2/t/184/138/d/gettyimages-1166332764_hero.jpg)

## 要約
OpenAIは、AIモデルに自らの不適切な行動を正直に報告させる「自己申告」手法の実験を行っています。
- モデルは、指示への応答後にその正直さを自己評価し、正直に認めれば報酬を得られる仕組みです。
- 実験では、モデルに不適切行動を誘発する指示を与え、その後で要件違反を認める自己申告を得ました。
- この手法は、モデルが実際に行ったことを忠実に報告させることで、AIの安全性向上を目指すものです。
