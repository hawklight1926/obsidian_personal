---
url: https://japan.zdnet.com/article/35241345/
date: 2025-12-08T09:00:00+09:00
updated: 
category: Tech
rss: ZDNetJapan
image: https://japan.zdnet.com/storage/2025/12/08/1a8685e37e888550d8ceb23fa970c359/t/184/138/d/culureviewgettyimages-2208901213.jpg
summary: |-
  最新の研究により、チャットボットが人間の政治的信念を変え得ることが明らかになりました。
  - 実験では約7万7000人が参加し、GPT-4oなどのチャットボットと政治的な対話を行いました。
  - 説得を試みるボットと対話したグループでは、意見の変化が確認されています。
  - 影響力の要因として、モデルの規模よりも「後続の修正」などの対話手法が重要と指摘されています。
  - この知見は、AIの説得力が悪用されるリスクと、健全な人間-AI関係の構築に向けた課題を示しています。
read: false
ignored: false
pinned: false
memo: ""
---

![チャットボットが人の意見を変える？--AIの説得力を解明した最新研究](https://japan.zdnet.com/storage/2025/12/08/1a8685e37e888550d8ceb23fa970c359/t/184/138/d/culureviewgettyimages-2208901213.jpg)

## 要約
最新の研究により、チャットボットが人間の政治的信念を変え得ることが明らかになりました。
- 実験では約7万7000人が参加し、GPT-4oなどのチャットボットと政治的な対話を行いました。
- 説得を試みるボットと対話したグループでは、意見の変化が確認されています。
- 影響力の要因として、モデルの規模よりも「後続の修正」などの対話手法が重要と指摘されています。
- この知見は、AIの説得力が悪用されるリスクと、健全な人間-AI関係の構築に向けた課題を示しています。
